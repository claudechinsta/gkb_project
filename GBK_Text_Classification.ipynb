{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification and Machine Learning\n",
    "*Research Project 2017 - Boya Chen*\n",
    "\n",
    "This section will do dataset preparation, classifier building and data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from time import time\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Reading CSV and prepare data\n",
    "\n",
    "[OUTPUT] labels, t_labels, t_pos, p_labels, p_pos,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Preparin Dataset]: ... ...\n",
      "[Preparation Completed]: 2.63643598557 s\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter, defaultdict\n",
    "from textblob import TextBlob as tb\n",
    "from time import time\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# GEO for Geolocation related classes\n",
    "# APP for Appearance related classes\n",
    "GEO = 0\n",
    "APP = 1\n",
    "\n",
    "TOPIC = GEO\n",
    "\n",
    "##########################################\n",
    "#  Prepare training and prediction data  #\n",
    "##########################################\n",
    "t1 = time(); print '[Preparin Dataset]: ... ...'\n",
    "\n",
    "content = []\n",
    "with open('./dataset.txt', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        content.append(row)\n",
    "\n",
    "# Acquire the list of labels\n",
    "labels = []\n",
    "for item in content:\n",
    "    labels.append(item[TOPIC])\n",
    "\n",
    "# Acquire raw sentences\n",
    "sents = []\n",
    "for item in content:\n",
    "    sents.append(item[2])\n",
    "    \n",
    "# Read Pre-processed and Cleaned Sents\n",
    "cleaned_sents = []\n",
    "with open(\"./cleaned_sents.csv\", \"rb\") as f:\n",
    "    csvReader = csv.reader(f)\n",
    "    for row in csvReader:\n",
    "        cleaned_sents.append(row)\n",
    "\n",
    "# Acquire ent for each sentences\n",
    "with open(\"./entities_set.json\", \"rb\") as f:\n",
    "    ent_with_info = json.load(f)    \n",
    "ent_sents = []\n",
    "for item in content:\n",
    "    ent_sents.append(item[3])\n",
    "type_sents = []\n",
    "for item in ent_sents:\n",
    "    try:\n",
    "        type_feat = defaultdict()\n",
    "        for t in ent_with_info[item]['ent_type']:\n",
    "            type_feat[t] = 1\n",
    "        type_sents.append(type_feat)\n",
    "    except:\n",
    "        type_sents.append({})\n",
    "\n",
    "# Acquire POS tags\n",
    "pos_sents = []\n",
    "with open('./training_pos_tag.csv', 'rb') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        pos_sents.append(row)\n",
    "\n",
    "# Splitting the data\n",
    "cut_num = 17000 # | 0~cut_num --> Training; cut_num~end --> Prediction(unlabeled)\n",
    "t_labels = np.array(labels[:cut_num])\n",
    "t_sents = np.array(sents[:cut_num])\n",
    "t_pos_sents = np.array(pos_sents[:cut_num])\n",
    "\n",
    "# Rest of sentences are for prediction\n",
    "p_sents = np.array(sents[cut_num:])\n",
    "p_pos_sents = np.array(pos_sents[cut_num:])\n",
    "\n",
    "print '[Preparation Completed]:', time()-t1, \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !------- Imbalance Classification Handling ---------!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of positive documents: 1016\n",
      "size of negative documents: 2032\n",
      "size of training dataset: 3048\n"
     ]
    }
   ],
   "source": [
    "index_of_t = [l for l in range(len(t_labels)) if t_labels[l] == \"t\"]\n",
    "index_of_f = [l for l in range(len(t_labels)) if t_labels[l] == \"f\"]\n",
    "random.shuffle(index_of_f)\n",
    "# Resample from the labeled data\n",
    "index_of_f = index_of_f[:len(index_of_t) * 2]\n",
    "index_of_resample = list(sorted(index_of_t + index_of_f))\n",
    "t_labels_resample = [t_labels[i] for i in range(len(t_labels)) if i in index_of_resample]\n",
    "\n",
    "print \"size of positive documents:\", len(index_of_t)\n",
    "print \"size of negative documents:\", len(index_of_f)\n",
    "print \"size of training dataset:\", len(t_labels_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [1] BAG OF WORDS - vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sents_with_t = [cleaned_sents[l] for l in range(len(cleaned_sents)) if labels[l] == 't']\n",
    "# words_with_t = []\n",
    "# for sent in sents_with_t:\n",
    "#     words_with_t.extend(sent)\n",
    "# words_freq = Counter()\n",
    "# for word in words_with_t:\n",
    "#     words_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Building Dataset] ... ...\n",
      "[Building Accomplished] --- 8.38937711716 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<17000x60147 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 194240 stored elements in Compressed Sparse Row format>,\n",
       " <3048x60147 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 36772 stored elements in Compressed Sparse Row format>,\n",
       " <76994x60147 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 901587 stored elements in Compressed Sparse Row format>,\n",
       " <93994x60147 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 1095827 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_BOW(text):\n",
    "    BOW = {}\n",
    "    for word in text:\n",
    "        BOW[word] = BOW.get(word,0) + 1\n",
    "    return BOW\n",
    "\n",
    "def prep_train_date(data):\n",
    "    feature_matrix = [get_BOW(line) for line in data]\n",
    "    \n",
    "    vectorizer = DictVectorizer()\n",
    "    dataset = vectorizer.fit_transform(feature_matrix)\n",
    "#     transformer = TfidfTransformer(smooth_idf=True)\n",
    "#     dataset = transformer.fit_transform(dataset)\n",
    "    return dataset\n",
    "\n",
    "print \"[Building Dataset] ... ...\"\n",
    "t1 = time()\n",
    "dataset_1 = prep_train_date(cleaned_sents)\n",
    "t_dataset_1 = dataset_1[:len(t_labels)]\n",
    "p_dataset_1 = dataset_1[len(t_labels):]\n",
    "\n",
    "t_dataset_1_r = csr_matrix([dataset_1[i].toarray()[0] for i in index_of_resample])\n",
    "\n",
    "print \"[Building Accomplished] ---\", time()-t1, 's'\n",
    "\n",
    "t_dataset_1, t_dataset_1_r, p_dataset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2]  Bag of Word - N-gram + vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "TIME: 85.5692539215 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<17000x656284 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 189809 stored elements in Compressed Sparse Row format>,\n",
       " <3048x656284 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 36301 stored elements in Compressed Sparse Row format>,\n",
       " <76994x656284 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 883730 stored elements in Compressed Sparse Row format>,\n",
       " 17000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################\n",
    "#  Preparing Training Data with Vectorization  #\n",
    "################################################\n",
    "def get_bag_of_ngram(text, n):\n",
    "    ngram_cnt = Counter()\n",
    "    for i in range(len(text)-(n-1)):\n",
    "        ngram_cnt[tuple(text[i:i+n])] += 1\n",
    "    return ngram_cnt\n",
    "\n",
    "def prep_train_date(data):\n",
    "    feature_matrix = [get_bag_of_ngram(sent, 2) for sent in data]\n",
    "    vectorizer = DictVectorizer()\n",
    "    dataset = vectorizer.fit_transform(feature_matrix)\n",
    "    return dataset\n",
    "\n",
    "t0 = time()\n",
    "# -- Call the Function\n",
    "dataset_2 = prep_train_date(cleaned_sents)\n",
    "\n",
    "# Split the dataset into TRAINING and PREDICTION datasets\n",
    "t_dataset_2 = dataset_2[:len(t_labels)]\n",
    "p_dataset_2 = dataset_2[len(t_labels):]\n",
    "\n",
    "t_dataset_2_r = csr_matrix([dataset_2[i].toarray()[0] for i in index_of_resample])\n",
    "\n",
    "print \"-\"*50\n",
    "print \"TIME:\", time()-t0, \"s\"\n",
    "\n",
    "t_dataset_2, t_dataset_2_r, p_dataset_2, len(t_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3] BAG OF POS TAGS - bigram | vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Dataset ... ...\n",
      "done -- 4.88035583496 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<93994x35 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 822843 stored elements in Compressed Sparse Row format>,\n",
       " <3048x35 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 26895 stored elements in Compressed Sparse Row format>,\n",
       " <17000x35 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 146857 stored elements in Compressed Sparse Row format>,\n",
       " <76994x35 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 675986 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire Bag of Pos-tags\n",
    "def get_ngram_POS(poses, n):\n",
    "    pos_cnt = Counter()\n",
    "    for i in range(len(poses)-(n-1)):\n",
    "        pos_cnt[tuple(poses[i:i+n])] += 1\n",
    "    return pos_cnt\n",
    "    \n",
    "def prep_train_date(data):\n",
    "    feature_matrix = [get_ngram_POS(poses, 1) for poses in data]\n",
    "\n",
    "    vectorizer = DictVectorizer()\n",
    "    dataset = vectorizer.fit_transform(feature_matrix)\n",
    "#     transformer = TfidfTransformer(smooth_idf=False)\n",
    "#     dataset = transformer.fit_transform(dataset)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# -- set time break\n",
    "t1 = time()\n",
    "print 'Building Dataset ... ...'\n",
    "\n",
    "# Dataset\n",
    "dataset_3 = prep_train_date(pos_sents)\n",
    "# Splitting Dataset\n",
    "t_dataset_3 = dataset_3[:cut_num]\n",
    "p_dataset_3 = dataset_3[cut_num:]\n",
    "\n",
    "t_dataset_3_r = csr_matrix([dataset_3[i].toarray()[0] for i in index_of_resample])\n",
    "\n",
    "print 'done --', time()-t1, 's'\n",
    "\n",
    "dataset_3, t_dataset_3_r, t_dataset_3, p_dataset_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4] Entities Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<93994x25 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 114223 stored elements in Compressed Sparse Row format>,\n",
       " <3048x25 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 3207 stored elements in Compressed Sparse Row format>,\n",
       " <17000x25 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 16995 stored elements in Compressed Sparse Row format>,\n",
       " <76994x25 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 97228 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_train_date(data):\n",
    "    # data is formed like (data[0], data[1])\n",
    "    # data[0] is list of POS tag list of each sentence\n",
    "    # data[1] is the labels\n",
    "    feature_matrix = data\n",
    "\n",
    "    vectorizer = DictVectorizer()\n",
    "    dataset = vectorizer.fit_transform(feature_matrix)\n",
    "#     transformer = TfidfTransformer(smooth_idf=False)\n",
    "#     dataset = transformer.fit_transform(dataset)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset_4 = prep_train_date(type_sents)\n",
    "t_dataset_4 = dataset_4[:cut_num]\n",
    "p_dataset_4 = dataset_4[cut_num:]\n",
    "\n",
    "t_dataset_4_r = csr_matrix([dataset_4[i].toarray()[0] for i in index_of_resample])\n",
    "\n",
    "dataset_4, t_dataset_4_r, t_dataset_4, p_dataset_4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F] Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<93994x60207 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 2032893 stored elements in COOrdinate format>,\n",
       " <17000x60207 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 358092 stored elements in COOrdinate format>,\n",
       " <3048x60207 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 66874 stored elements in COOrdinate format>,\n",
       " <76994x60207 sparse matrix of type '<type 'numpy.float64'>'\n",
       " \twith 1674801 stored elements in COOrdinate format>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = hstack((dataset_1, dataset_3, dataset_4))\n",
    "t_dataset = hstack((t_dataset_1, t_dataset_3, t_dataset_4))\n",
    "t_dataset_r = hstack((t_dataset_1_r, t_dataset_3_r, t_dataset_4_r))\n",
    "p_dataset = hstack((p_dataset_1, p_dataset_3, p_dataset_4))\n",
    "\n",
    "dataset, t_dataset, t_dataset_r, p_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading entities sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3591 3643\n"
     ]
    }
   ],
   "source": [
    "# Input Entity name to locate the entity section in the whole dataset\n",
    "name_to_node = defaultdict()\n",
    "for key in ent_with_info:\n",
    "    try:\n",
    "        name_to_node[ent_with_info[key]['tag']['name']] = key\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print len(name_to_node.keys()), len(ent_with_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "# from osmapi import OsmApi\n",
    "# MyApi = OsmApi()\n",
    "\n",
    "# ent_with_info = defaultdict()\n",
    "# flag = 0\n",
    "# t1 = time()\n",
    "# print '[Reading OSM info] ... ...'\n",
    "# for nodeName in node_list:\n",
    "#     try:\n",
    "#         if 'node' in nodeName:\n",
    "#             nodeId = nodeName[5:]\n",
    "#             ent_with_info[nodeName] = MyApi.NodeGet(nodeId)\n",
    "#         else:\n",
    "#             nodeId = nodeName[4:]\n",
    "#             ent_with_info[nodeName] = MyApi.WayGet(nodeId)\n",
    "#     except:\n",
    "#         print '*Problem At:', nodeName\n",
    "#         ent_with_info[nodeName] = {}\n",
    "#     flag += 1\n",
    "#     if flag%40 == 0:\n",
    "#         print str(round(float(flag)/len(node_list)*100, 2))+'%', \"- loaded\"\n",
    "\n",
    "# for key in ent_with_info:\n",
    "#     try:\n",
    "#         ent_with_info[key]['timestamp'] = str(ent_with_info[key]['timestamp'])\n",
    "#     except:\n",
    "#         continue\n",
    "        \n",
    "# with open(\"./entities_set.json\", \"wb\") as output:\n",
    "#     json.dump(ent_with_info, output)\n",
    "\n",
    "# print '[Completed]', time()-t1, 's'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Classification and machine leanring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_results(predictions, classifications):\n",
    "    lab = ['t', 'f']\n",
    "    print \"accuracy\"\n",
    "#     print accuracy_score(classifications, predictions)\n",
    "    print classification_report(classifications, predictions, labels=lab)\n",
    "\n",
    "def error_checking(real_predictions, labels, verbose):\n",
    "    t_t = len([i for i in range(len(real_predictions)) if real_predictions[i] == 't' and labels[i] == 't'])\n",
    "    f_f = len([i for i in range(len(real_predictions)) if real_predictions[i] == 'f' and labels[i] == 'f'])\n",
    "    t_f = len([i for i in range(len(real_predictions)) if real_predictions[i] == 'f' and labels[i] == 't'])\n",
    "    f_t = len([i for i in range(len(real_predictions)) if real_predictions[i] == 't' and labels[i] == 'f'])\n",
    "\n",
    "    print '--Correct--'\n",
    "    print 'True --> True:', t_t\n",
    "    print 'False --> False:', f_f\n",
    "    print ''\n",
    "    print '--Incorrect--'\n",
    "    print 'True --> False:', t_f\n",
    "    print 'False --> True:', f_t\n",
    "    print ''\n",
    "    print '--> Accuracy:', round((t_t+f_f) / float(t_t+t_f+f_t+f_f) , 2)\n",
    "    print '--> Precision:', round(t_t / float(t_t+f_t) , 2 )\n",
    "    print '--> Recall:', round(t_t / float(t_t+t_f), 2 )\n",
    "    print ''\n",
    "    \n",
    "    if len(verbose) == 2:\n",
    "        test_case = [l for l in verbose]\n",
    "        print \"Sentence: \",test_case[0],\"-->\",test_case[1]\n",
    "        print \"-\"*80\n",
    "        for i, sent in enumerate(sents[:len(real_predictions)]):\n",
    "            if real_predictions[i] == test_case[1] and labels[i] == test_case[0]:\n",
    "                print '>', i, '\\t|  ', sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER --> LinearSVC(C=0.1, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "accuracy\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          t       0.85      0.88      0.86      1016\n",
      "          f       0.94      0.92      0.93      2032\n",
      "\n",
      "avg / total       0.91      0.91      0.91      3048\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "CLASSIFIER --> RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "accuracy\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          t       0.91      0.74      0.82      1016\n",
      "          f       0.88      0.96      0.92      2032\n",
      "\n",
      "avg / total       0.89      0.89      0.89      3048\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "CLASSIFIER --> KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n",
      "accuracy\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          t       0.72      0.88      0.80      1016\n",
      "          f       0.93      0.83      0.88      2032\n",
      "\n",
      "avg / total       0.86      0.85      0.85      3048\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "############################\n",
    "# Classifiers from Sklearn #\n",
    "############################\n",
    "# # Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_nb = MultinomialNB()\n",
    "\n",
    "# Support Vector Machine\n",
    "from sklearn import svm\n",
    "clf_svm = svm.LinearSVC(C=0.1)\n",
    "\n",
    "# # --- Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "# # --- Random Foreset Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rfc = RandomForestClassifier()\n",
    "\n",
    "# # --- Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier()\n",
    "\n",
    "# K Neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_knc = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# --- Cross Validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "test_clf = [clf_svm, clf_rfc, clf_knc]\n",
    "for clf in test_clf:\n",
    "    print 'CLASSIFIER -->', str(clf)\n",
    "#     print '------- CROSS VALIDATION --------'\n",
    "    crossval_predicted = cross_val_predict(clf, t_dataset_r, t_labels_resample, cv=10)\n",
    "    check_results(crossval_predicted, t_labels_resample)\n",
    "    print '-'*100\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2 Predict whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76994, 60207)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Classifier\n",
    "clf_is_fit = 0\n",
    "if clf_is_fit == 1:\n",
    "    print \"#\"*10, \"PREDICTION SUMMARY\", \"#\"*10\n",
    "    real_predictions = clf_rfc.fit(t_dataset_r, t_labels_resample).predict(p_dataset)\n",
    "\n",
    "for i, l in enumerate(real_predictions):\n",
    "    if l == \"t\":\n",
    "        print \">\", i+cut_num, \"|\", sents[i+cut_num]\n",
    "# check_results(real_predictions, t_labels)    \n",
    "\n",
    "# # print \"Size of Dataset \\t\\t|\", t_dataset_1.shape[0]\n",
    "# # print ''\n",
    "\n",
    "# # Print all the entity's sentences\n",
    "# print len(real_predictions), len(t_labels)\n",
    "# error_checking(real_predictions, t_labels, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real World Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This phase will use the classifiers to train the real-world (unlabelled data)\n",
    "real_predictions = clf_rfc.fit(t_dataset_r, t_labels_resample).predict(p_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# p_content = content[cut_num:]\n",
    "# for i in range(len(p_sents)): \n",
    "#     if real_predictions[i] == 't':\n",
    "#         print i,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e_names = name_to_node.keys()\n",
    "random.shuffle(e_names)\n",
    "print \"Query:\\t\\t\", e_names[0], \"\\nEntityId:\\t\", name_to_node[e_names[0]]\n",
    "chosen_node = name_to_node[e_names[0]]\n",
    "print ''\n",
    "\n",
    "p_content = content[cut_num:]\n",
    "\n",
    "for i in range(len(p_sents)):\n",
    "    cnt = 0\n",
    "    if p_content[i][3] == chosen_node:\n",
    "        cnt += 1\n",
    "        if real_predictions[i] == 'f':\n",
    "            print '[x]', i+cut_num, \"||\",  p_sents[i]\n",
    "        elif real_predictions[i] == 't':\n",
    "            print '\\n', '~' * 80\n",
    "            print '[v]', i+cut_num, \"||\",  p_sents[i]\n",
    "            print '~' * 80\n",
    "            print ''\n",
    "\n",
    "if cnt == 0:\n",
    "    print \"[error] the query is not the p rediction section\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
